
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../../model-list/">
      
      
        <link rel="next" href="../../02-model-behaviour-level-simulation/llm-bitflip/">
      
      
      <link rel="icon" href="../../images/logo.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.12">
    
    
      
        <title>LLM Pretraining and Evaluation - NewComputeBench</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.2afb09e1.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="deep-orange">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#llm-pretraining" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="NewComputeBench" class="md-header__button md-logo" aria-label="NewComputeBench" data-md-component="logo">
      
  <img src="../../images/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            NewComputeBench
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              LLM Pretraining and Evaluation
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/AICrossSim/NewComputeBench" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    NewComputeBench
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../env-setup/" class="md-tabs__link">
          
  
  
  Getting Started

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../dev-guide/" class="md-tabs__link">
          
  
  
  Developer Guide

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="NewComputeBench" class="md-nav__button md-logo" aria-label="NewComputeBench" data-md-component="logo">
      
  <img src="../../images/logo.png" alt="logo">

    </a>
    NewComputeBench
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/AICrossSim/NewComputeBench" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    NewComputeBench
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Getting Started
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Getting Started
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../env-setup/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Environment Setup
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../model-list/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Supported Models
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3" checked>
        
          
          <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Pretraining
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            Pretraining
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    LLM Pretraining and Evaluation
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    LLM Pretraining and Evaluation
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#overview" class="md-nav__link">
    <span class="md-ellipsis">
      Overview
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pretraining" class="md-nav__link">
    <span class="md-ellipsis">
      Pretraining
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Pretraining">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#aicrosssim-clm-60m" class="md-nav__link">
    <span class="md-ellipsis">
      AICrossSim-CLM-60M
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#aicrosssim-clm-200m" class="md-nav__link">
    <span class="md-ellipsis">
      AICrossSim-CLM-200M
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#aicrosssim-clm-400m" class="md-nav__link">
    <span class="md-ellipsis">
      AICrossSim-CLM-400M
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#aicrosssim-clm-11b" class="md-nav__link">
    <span class="md-ellipsis">
      AICrossSim-CLM-1.1B
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evaluation" class="md-nav__link">
    <span class="md-ellipsis">
      Evaluation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Evaluation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pretraining-dataset-perplexity" class="md-nav__link">
    <span class="md-ellipsis">
      Pretraining Dataset Perplexity
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#downstream-tasks" class="md-nav__link">
    <span class="md-ellipsis">
      Downstream Tasks
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#simple-generation" class="md-nav__link">
    <span class="md-ellipsis">
      Simple Generation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_4" >
        
          
          <label class="md-nav__link" for="__nav_2_4" id="__nav_2_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Model Behaviour Level Simulation
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_4">
            <span class="md-nav__icon md-icon"></span>
            Model Behaviour Level Simulation
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_4_1" >
        
          
          <label class="md-nav__link" for="__nav_2_4_1" id="__nav_2_4_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Random BitFlip
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_4_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_4_1">
            <span class="md-nav__icon md-icon"></span>
            Random BitFlip
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../02-model-behaviour-level-simulation/llm-bitflip/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    LLM
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../03-hardware-performance-simulation/underconstruction/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Hardware Performance Simulation
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Developer Guide
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Developer Guide
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dev-guide/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Maintaining Docs
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../02-model-behaviour-level-simulation/llm-optical-dev-guidelines/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Transform-aware Training of LLMs
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/AICrossSim/NewComputeBench/edit/master/docs/01-model-training/llm-pretrain-and-eval.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/AICrossSim/NewComputeBench/raw/master/docs/01-model-training/llm-pretrain-and-eval.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg>
    </a>
  


<h1 id="llm-pretraining">LLM Pretraining</h1>
<p>This is a tutorial on how to pretrain <a href="../../model-list/">AICrossSim-CLM</a> using NewComputeBench.</p>
<h2 id="overview">Overview</h2>
<ul>
<li>We aim to pretrain AICrossSim-CLM models (60M, 200M, 400M, 1.1B) on the <a href="https://huggingface.co/datasets/HuggingFaceFW/fineweb-edu">Fineweb-Edu</a> dataset.<ul>
<li>We followed the <a href="https://arxiv.org/abs/2203.15556">Chinchilla scaling law</a> to determine the number of training tokens: <code>num_tokens = 22 * num_params</code>.</li>
<li>As the model size increases, the training time and memory requirements will increase significantly. For example, we pretrained the 1.1B model on 8 NVIDIA H100 80GB GPUs for 1.4 days, while the 60M model can be pretrained on 2 NVIDIA H100 80GB GPUs within 1 hour.</li>
</ul>
</li>
<li>The pretraining entrypoint is at <code>experiments/llm-digital/pretrain/run.py</code><ul>
<li><code>run.py</code> supports multiple subcommands, including <code>pretrain</code>, <code>eval</code>, <code>generate-hf</code>, <code>convert-ckpt</code>, and <code>generate-cfg</code>.<ul>
<li>Run <code>python run.py -h</code> to see the available subcommands.</li>
<li>Run <code>python run.py &lt;subcommand&gt; -h</code> to see the help message for a specific subcommand.</li>
</ul>
</li>
<li>To run distributed training, we use <code>torchrun</code> to launch the training script.</li>
</ul>
</li>
<li>We uploaded the pretrained models to HuggingFace for easy access: <a href="https://huggingface.co/collections/AICrossSim/newcomputebench-clm-digital-67d19e95ebacdbc3e5752be3">NewComputeBench-CLM-Digital</a></li>
</ul>
<h2 id="pretraining">Pretraining</h2>
<div class="admonition info">
<p class="admonition-title">Environment Setup?</p>
<p>If you have not set up environments, please follow the guidelines in <a href="../../env-setup/">Environment Setup</a>.</p>
</div>
<h3 id="aicrosssim-clm-60m">AICrossSim-CLM-60M</h3>
<p>We demonstrate the pretraining process using the <code>AICrossSim-CLM-60M</code> model. The same process can be applied to other models with minor adjustments.</p>
<ol>
<li>
<p>Change the working directory to <code>experiments/llm-digital/pretrain</code> and activate the conda environment.</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nb">cd</span><span class="w"> </span>experiments/llm-digital/pretrain
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>conda<span class="w"> </span>activate<span class="w"> </span>new-compute
</span></code></pre></div>
</li>
<li>
<p>Generate pretraining config</p>
<div class="admonition info">
<p class="admonition-title">Fast Development Run?</p>
<p><code>generate-cfg</code> has several default arguments. You may want to change them for a fast development run:</p>
<ul>
<li><code>--batch_size</code>: a smaller batch size to avoid out-of-memory errors.</li>
<li><code>--data_parallel_replicate_degree</code>: partition the training data across multiple GPUs. Each GPU receives a subset of the training data.</li>
<li><code>--data_parallel_shard_degree</code>: partition the model parameters across multiple GPUs. Each GPU receives a subset of the model parameters. Default <code>-1</code> means no sharding.</li>
<li><code>--token_num_scale</code>: the scale used to determine the number of training tokens: <code>num_tokens = token_num_scale * num_params</code>, 22 by default. Set this to a small value like <code>1</code> to reduce the number of training steps.</li>
</ul>
</div>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="nv">data_parallel</span><span class="o">=</span><span class="s2">&quot;2&quot;</span><span class="w">       </span><span class="c1"># For Simplicity, we set this to number of GPUs per node</span>
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a><span class="nv">batch_size</span><span class="o">=</span><span class="s2">&quot;48&quot;</span><span class="w">         </span><span class="c1"># Per-device batch size</span>
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a><span class="nv">token_num_scale</span><span class="o">=</span><span class="s2">&quot;22&quot;</span><span class="w">    </span><span class="c1"># Scale for number of training tokens</span>
</span><span id="__span-1-4"><a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a>python<span class="w"> </span>run.py<span class="w"> </span>generate-cfg<span class="w"> </span><span class="se">\</span>
</span><span id="__span-1-5"><a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a><span class="w">    </span>--model_flavor<span class="w"> </span>60M<span class="w"> </span>--batch_size<span class="w"> </span><span class="si">${</span><span class="nv">batch_size</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-1-6"><a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a><span class="w">    </span>--data_parallel_replicate_degree<span class="w"> </span><span class="si">${</span><span class="nv">data_parallel</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-1-7"><a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a><span class="w">    </span>--compile<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-1-8"><a id="__codelineno-1-8" name="__codelineno-1-8" href="#__codelineno-1-8"></a><span class="w">    </span>--save_path<span class="w"> </span>./configs/tutorial-60M.yaml
</span></code></pre></div>
<ul>
<li>This will generate a training configuration file <code>configs/tutorial-60M.yaml</code> for pretraining <code>AICrossSim-CLM-60M</code> model using a per-device batch size of 48 and a data parallel replicate degree of 2 on a FineWeb-Edu subset of <code>22 * 60M</code> tokens.</li>
<li>Subcommand <code>generate-cfg</code> automatically calculates the number of training steps.</li>
<li>The <code>--compile</code> flag enables the use of <code>torch.compile</code> for optimizing the training process.</li>
</ul>
</li>
<li>
<p>Launch pretraining</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="nv">num_gpus</span><span class="o">=</span><span class="s2">&quot;2&quot;</span><span class="w"> </span><span class="c1"># Number of GPUs per node. We only use one node for this example</span>
</span><span id="__span-2-2"><a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a><span class="nv">PYTORCH_CUDA_ALLOC_CONF</span><span class="o">=</span><span class="s2">&quot;expandable_segments:True&quot;</span><span class="w"> </span><span class="nv">STREAM_HF_DATA</span><span class="o">=</span><span class="s2">&quot;1&quot;</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-2-3"><a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a>torchrun<span class="w"> </span>--nproc_per_node<span class="o">=</span><span class="si">${</span><span class="nv">num_gpus</span><span class="si">}</span><span class="w"> </span>--rdzv_backend<span class="w"> </span>c10d<span class="w"> </span><span class="se">\</span>
</span><span id="__span-2-4"><a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a><span class="w">    </span>--rdzv_endpoint<span class="o">=</span><span class="s2">&quot;localhost:0&quot;</span><span class="w"> </span>--local-ranks-filter<span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-2-5"><a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a><span class="w">    </span>--role<span class="w"> </span>rank<span class="w"> </span>--tee<span class="w"> </span><span class="m">3</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-2-6"><a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a><span class="w">    </span>run.py<span class="w"> </span>pretrain<span class="w"> </span>--config<span class="w"> </span>configs/tutorial-60M.yaml<span class="w"> </span><span class="se">\</span>
</span><span id="__span-2-7"><a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a><span class="w">    </span>--metrics_args.enable_wandb<span class="w"> </span><span class="nb">false</span><span class="w"> </span><span class="c1"># disable wandb in case the user does not log in wandb</span>
</span></code></pre></div>
<ul>
<li>This will pass the generated configuration file and launch the pretraining job on a single node of 2 GPUs using <code>torchrun</code>.</li>
<li>The <code>--metrics_args.enable_wandb</code> flag disables Weights and Biases logging. You can enable it by setting it to <code>true</code>.</li>
<li>The <code>STREAM_HF_DATA</code> environment variable is set to <code>1</code> to enable streaming data loading from Hugging Face datasets instead of downloading the huge dataset to the local disk.</li>
<li>When the training is finished, the model checkpoint will be saved at <code>./outputs/checkpoints/aixsim-60M/&lt;timestamp&gt;</code>.</li>
</ul>
<details class="failure">
<summary>Fatal Python error: Aborted ?</summary>
<p>We noticed that after the training is finished, <code>torchrun</code> may raise the error "Fatal Python error: Aborted" when destroying process group. <strong>This does not affect the training results as long as the error is raised after the final checkpoint is saved</strong> (messages like "[rank0]:2025-04-01 00:25:59,616 - root - INFO - Finished saving the checkpoint (or staging if async is enabled)in 5.53 seconds.")</p>
<p>Here is an example of the error message:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a>[rank0]:2025-04-01 00:25:47,084 - root - INFO - step: 640/644 = 99.3789%  loss:  6.2116  memory: 87.04GiB(93.48%)  tps: 52,142  mfu: 3.09%
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a>[rank0]:2025-04-01 00:25:54,090 - root - INFO - Saving a full checkpoint at last step, step 644.
</span><span id="__span-3-3"><a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a>[rank0]:2025-04-01 00:25:59,616 - root - INFO - Finished saving the checkpoint (or staging if async is enabled)in 5.53 seconds.
</span><span id="__span-3-4"><a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a>[rank0]:2025-04-01 00:25:59,617 - root - INFO - Sleeping 2 seconds for other ranks to complete
</span><span id="__span-3-5"><a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a>[rank0]:2025-04-01 00:26:01,706 - root - INFO - Training completed
</span><span id="__span-3-6"><a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a>[rank0]:terminate called without an active exception
</span><span id="__span-3-7"><a id="__codelineno-3-7" name="__codelineno-3-7" href="#__codelineno-3-7"></a>[rank0]:Fatal Python error: Aborted
</span><span id="__span-3-8"><a id="__codelineno-3-8" name="__codelineno-3-8" href="#__codelineno-3-8"></a>[rank0]:
</span><span id="__span-3-9"><a id="__codelineno-3-9" name="__codelineno-3-9" href="#__codelineno-3-9"></a>[rank0]:Current thread 0x00007f0360ff9640 (most recent call first):
</span><span id="__span-3-10"><a id="__codelineno-3-10" name="__codelineno-3-10" href="#__codelineno-3-10"></a>[rank0]:  Garbage-collecting
</span><span id="__span-3-11"><a id="__codelineno-3-11" name="__codelineno-3-11" href="#__codelineno-3-11"></a>[rank0]:  &lt;no Python frame&gt;
</span><span id="__span-3-12"><a id="__codelineno-3-12" name="__codelineno-3-12" href="#__codelineno-3-12"></a>[rank0]:
</span><span id="__span-3-13"><a id="__codelineno-3-13" name="__codelineno-3-13" href="#__codelineno-3-13"></a>[rank0]:Thread 0x00007f06b6639200 (most recent call first):
</span><span id="__span-3-14"><a id="__codelineno-3-14" name="__codelineno-3-14" href="#__codelineno-3-14"></a>[rank0]:  &lt;no Python frame&gt;
</span><span id="__span-3-15"><a id="__codelineno-3-15" name="__codelineno-3-15" href="#__codelineno-3-15"></a>W0401 00:26:06.901000 3016633 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 3016738 closing signal SIGTERM
</span><span id="__span-3-16"><a id="__codelineno-3-16" name="__codelineno-3-16" href="#__codelineno-3-16"></a>E0401 00:26:08.212000 3016633 site-packages/torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: -6) local_rank: 1 (pid: 3016739) of binary: /home/zz7522/miniconda3/envs/new-compute/bin/python3.11
</span><span id="__span-3-17"><a id="__codelineno-3-17" name="__codelineno-3-17" href="#__codelineno-3-17"></a>Traceback (most recent call last):
</span><span id="__span-3-18"><a id="__codelineno-3-18" name="__codelineno-3-18" href="#__codelineno-3-18"></a>File &quot;/home/zz7522/miniconda3/envs/new-compute/bin/torchrun&quot;, line 8, in &lt;module&gt;
</span><span id="__span-3-19"><a id="__codelineno-3-19" name="__codelineno-3-19" href="#__codelineno-3-19"></a>    sys.exit(main())
</span><span id="__span-3-20"><a id="__codelineno-3-20" name="__codelineno-3-20" href="#__codelineno-3-20"></a>            ^^^^^^
</span><span id="__span-3-21"><a id="__codelineno-3-21" name="__codelineno-3-21" href="#__codelineno-3-21"></a>File &quot;/home/zz7522/miniconda3/envs/new-compute/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py&quot;, line 355, in wrapper
</span><span id="__span-3-22"><a id="__codelineno-3-22" name="__codelineno-3-22" href="#__codelineno-3-22"></a>    return f(*args, **kwargs)
</span><span id="__span-3-23"><a id="__codelineno-3-23" name="__codelineno-3-23" href="#__codelineno-3-23"></a>        ^^^^^^^^^^^^^^^^^^
</span><span id="__span-3-24"><a id="__codelineno-3-24" name="__codelineno-3-24" href="#__codelineno-3-24"></a>File &quot;/home/zz7522/miniconda3/envs/new-compute/lib/python3.11/site-packages/torch/distributed/run.py&quot;, line 918, in main
</span><span id="__span-3-25"><a id="__codelineno-3-25" name="__codelineno-3-25" href="#__codelineno-3-25"></a>    run(args)
</span><span id="__span-3-26"><a id="__codelineno-3-26" name="__codelineno-3-26" href="#__codelineno-3-26"></a>File &quot;/home/zz7522/miniconda3/envs/new-compute/lib/python3.11/site-packages/torch/distributed/run.py&quot;, line 909, in run
</span><span id="__span-3-27"><a id="__codelineno-3-27" name="__codelineno-3-27" href="#__codelineno-3-27"></a>    elastic_launch(
</span><span id="__span-3-28"><a id="__codelineno-3-28" name="__codelineno-3-28" href="#__codelineno-3-28"></a>File &quot;/home/zz7522/miniconda3/envs/new-compute/lib/python3.11/site-packages/torch/distributed/launcher/api.py&quot;, line 138, in __call__
</span><span id="__span-3-29"><a id="__codelineno-3-29" name="__codelineno-3-29" href="#__codelineno-3-29"></a>    return launch_agent(self._config, self._entrypoint, list(args))
</span><span id="__span-3-30"><a id="__codelineno-3-30" name="__codelineno-3-30" href="#__codelineno-3-30"></a>        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
</span><span id="__span-3-31"><a id="__codelineno-3-31" name="__codelineno-3-31" href="#__codelineno-3-31"></a>File &quot;/home/zz7522/miniconda3/envs/new-compute/lib/python3.11/site-packages/torch/distributed/launcher/api.py&quot;, line 269, in launch_agent
</span><span id="__span-3-32"><a id="__codelineno-3-32" name="__codelineno-3-32" href="#__codelineno-3-32"></a>    raise ChildFailedError(
</span><span id="__span-3-33"><a id="__codelineno-3-33" name="__codelineno-3-33" href="#__codelineno-3-33"></a>torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
</span><span id="__span-3-34"><a id="__codelineno-3-34" name="__codelineno-3-34" href="#__codelineno-3-34"></a>========================================================
</span><span id="__span-3-35"><a id="__codelineno-3-35" name="__codelineno-3-35" href="#__codelineno-3-35"></a>run.py FAILED
</span><span id="__span-3-36"><a id="__codelineno-3-36" name="__codelineno-3-36" href="#__codelineno-3-36"></a>--------------------------------------------------------
</span><span id="__span-3-37"><a id="__codelineno-3-37" name="__codelineno-3-37" href="#__codelineno-3-37"></a>Failures:
</span><span id="__span-3-38"><a id="__codelineno-3-38" name="__codelineno-3-38" href="#__codelineno-3-38"></a>&lt;NO_OTHER_FAILURES&gt;
</span><span id="__span-3-39"><a id="__codelineno-3-39" name="__codelineno-3-39" href="#__codelineno-3-39"></a>--------------------------------------------------------
</span><span id="__span-3-40"><a id="__codelineno-3-40" name="__codelineno-3-40" href="#__codelineno-3-40"></a>Root Cause (first observed failure):
</span><span id="__span-3-41"><a id="__codelineno-3-41" name="__codelineno-3-41" href="#__codelineno-3-41"></a>[0]:
</span><span id="__span-3-42"><a id="__codelineno-3-42" name="__codelineno-3-42" href="#__codelineno-3-42"></a>time      : 2025-04-01_00:26:06
</span><span id="__span-3-43"><a id="__codelineno-3-43" name="__codelineno-3-43" href="#__codelineno-3-43"></a>host      : ee-tiamat.ee.ic.ac.uk
</span><span id="__span-3-44"><a id="__codelineno-3-44" name="__codelineno-3-44" href="#__codelineno-3-44"></a>rank      : 1 (local_rank: 1)
</span><span id="__span-3-45"><a id="__codelineno-3-45" name="__codelineno-3-45" href="#__codelineno-3-45"></a>exitcode  : -6 (pid: 3016739)
</span><span id="__span-3-46"><a id="__codelineno-3-46" name="__codelineno-3-46" href="#__codelineno-3-46"></a>error_file: &lt;N/A&gt;
</span><span id="__span-3-47"><a id="__codelineno-3-47" name="__codelineno-3-47" href="#__codelineno-3-47"></a>traceback : Signal 6 (SIGABRT) received by PID 3016739
</span><span id="__span-3-48"><a id="__codelineno-3-48" name="__codelineno-3-48" href="#__codelineno-3-48"></a>========================================================
</span></code></pre></div>
</details>
</li>
<li>
<p>(Optional) Convert to HuggingFace checkpoint</p>
<div class="admonition info">
<p class="admonition-title">HuggingFace Checkpoint</p>
<p>To support distributed training, the training code defines custom model classes, and the checkpoints are saved in a custom format by <code>torchrun</code>.
To exploit the HuggingFace ecosystem, we provide a script to convert the custom checkpoint to HuggingFace format.</p>
</div>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a>python<span class="w"> </span>run.py<span class="w"> </span>convert-ckpt<span class="w"> </span>aixsim<span class="w"> </span>60M<span class="w"> </span><span class="se">\</span>
</span><span id="__span-4-2"><a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a><span class="w">    </span>./outputs/checkpoints/aixsim-60M/&lt;timestamp&gt;/&lt;step-xxx&gt;<span class="w"> </span><span class="se">\</span>
</span><span id="__span-4-3"><a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a><span class="w">    </span>path/to/huggingface/checkpoint
</span></code></pre></div>
</li>
</ol>
<div class="admonition success">
<p class="admonition-title">Our Pretraining Results</p>
<p>We pretrained the <code>AICrossSim-CLM-60M</code> model on 2 NVIDIA H100 96GB GPUs for 1 hour.</p>
<ul>
<li>Training config: <a href="https://github.com/AICrossSim/NewComputeBench/blob/master/experiments/llm-digital/pretrain/configs/aixsim-60M.yaml"><code>experiments/llm-digital/pretrain/configs/aixsim-60M.yaml</code></a></li>
<li>Wandb logs: <a href="https://wandb.ai/cz98/torchtitan/runs/7kttp3qt?nw=nwusercz98">link</a></li>
<li>HuggingFace checkpoint: <a href="https://huggingface.co/AICrossSim/clm-60m">AICrossSim/clm-60m</a></li>
</ul>
</div>
<p>Similarly, you can pretrain the other models by changing the <code>--model_flavor</code> argument to <code>200M</code>, <code>400M</code>, or <code>1.1B</code>, and adjusting <code>--batch_size</code>, <code>--data_parallel_replicate_degree</code>, <code>--data_parallel_shard_degree</code>, and <code>--token_num_scale</code> accordingly.</p>
<h3 id="aicrosssim-clm-200m">AICrossSim-CLM-200M</h3>
<p>We applied Fully Sharded Data Parallel (FSDP) to the <code>AICrossSim-CLM-200M</code> training job to reduce memory usage, but this increases the training time.</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a><span class="nv">batch_size</span><span class="o">=</span><span class="s2">&quot;32&quot;</span>
</span><span id="__span-5-2"><a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a><span class="nv">data_parallel_replicate</span><span class="o">=</span><span class="s2">&quot;1&quot;</span>
</span><span id="__span-5-3"><a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a><span class="nv">data_parallel_shard</span><span class="o">=</span><span class="s2">&quot;2&quot;</span>
</span><span id="__span-5-4"><a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a>python<span class="w"> </span>run.py<span class="w"> </span>generate-cfg<span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-5"><a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a><span class="w">    </span>--model_flavor<span class="w"> </span>200M<span class="w"> </span>--batch_size<span class="w"> </span><span class="si">${</span><span class="nv">batch_size</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-6"><a id="__codelineno-5-6" name="__codelineno-5-6" href="#__codelineno-5-6"></a><span class="w">    </span>--data_parallel_replicate_degree<span class="w"> </span><span class="si">${</span><span class="nv">data_parallel_replicate</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-7"><a id="__codelineno-5-7" name="__codelineno-5-7" href="#__codelineno-5-7"></a><span class="w">    </span>--data_parallel_shard_degree<span class="w"> </span><span class="si">${</span><span class="nv">data_parallel_shard</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-8"><a id="__codelineno-5-8" name="__codelineno-5-8" href="#__codelineno-5-8"></a><span class="w">    </span>--compile<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-9"><a id="__codelineno-5-9" name="__codelineno-5-9" href="#__codelineno-5-9"></a><span class="w">    </span>--save_path<span class="w"> </span>./configs/tutorial-200M.yaml
</span><span id="__span-5-10"><a id="__codelineno-5-10" name="__codelineno-5-10" href="#__codelineno-5-10"></a>
</span><span id="__span-5-11"><a id="__codelineno-5-11" name="__codelineno-5-11" href="#__codelineno-5-11"></a><span class="nv">num_gpus</span><span class="o">=</span><span class="s2">&quot;2&quot;</span><span class="w"> </span><span class="c1"># 2 GPUs, 1 node</span>
</span><span id="__span-5-12"><a id="__codelineno-5-12" name="__codelineno-5-12" href="#__codelineno-5-12"></a><span class="nv">PYTORCH_CUDA_ALLOC_CONF</span><span class="o">=</span><span class="s2">&quot;expandable_segments:True&quot;</span><span class="w"> </span><span class="nv">STREAM_HF_DATA</span><span class="o">=</span><span class="s2">&quot;1&quot;</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-13"><a id="__codelineno-5-13" name="__codelineno-5-13" href="#__codelineno-5-13"></a>torchrun<span class="w"> </span>--nproc_per_node<span class="o">=</span><span class="si">${</span><span class="nv">num_gpus</span><span class="si">}</span><span class="w"> </span>--rdzv_backend<span class="w"> </span>c10d<span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-14"><a id="__codelineno-5-14" name="__codelineno-5-14" href="#__codelineno-5-14"></a><span class="w">    </span>--rdzv_endpoint<span class="o">=</span><span class="s2">&quot;localhost:0&quot;</span><span class="w"> </span>--local-ranks-filter<span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-15"><a id="__codelineno-5-15" name="__codelineno-5-15" href="#__codelineno-5-15"></a><span class="w">    </span>--role<span class="w"> </span>rank<span class="w"> </span>--tee<span class="w"> </span><span class="m">3</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-16"><a id="__codelineno-5-16" name="__codelineno-5-16" href="#__codelineno-5-16"></a><span class="w">    </span>run.py<span class="w"> </span>pretrain<span class="w"> </span>--config<span class="w"> </span>configs/tutorial-200M.yaml<span class="w"> </span><span class="se">\</span>
</span><span id="__span-5-17"><a id="__codelineno-5-17" name="__codelineno-5-17" href="#__codelineno-5-17"></a><span class="w">    </span>--metrics_args.enable_wandb<span class="w"> </span><span class="nb">false</span>
</span></code></pre></div>
<div class="admonition success">
<p class="admonition-title">Our Pretraining Results</p>
<p>We pretrained the <code>AICrossSim-CLM-200M</code> model on 2 NVIDIA H100 96GB GPUs for 6.5 hours.</p>
<ul>
<li>Training config: <a href="https://github.com/AICrossSim/NewComputeBench/blob/master/experiments/llm-bitflip/pretrain/configs/aixsim-200M.yaml"><code>experiments/llm-bitflip/pretrain/configs/aixsim-200M.yaml</code></a></li>
<li>Wandb logs: <a href="https://wandb.ai/cz98/torchtitan/runs/uhnlw6k8/overview">link</a></li>
<li>HuggingFace checkpoint: <a href="https://huggingface.co/AICrossSim/clm-200m">AICrossSim/clm-200m</a></li>
</ul>
</div>
<h3 id="aicrosssim-clm-400m">AICrossSim-CLM-400M</h3>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a><span class="nv">batch_size</span><span class="o">=</span><span class="s2">&quot;12&quot;</span>
</span><span id="__span-6-2"><a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a><span class="nv">data_parallel_replicate</span><span class="o">=</span><span class="s2">&quot;1&quot;</span>
</span><span id="__span-6-3"><a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a><span class="nv">data_parallel_shard</span><span class="o">=</span><span class="s2">&quot;8&quot;</span>
</span><span id="__span-6-4"><a id="__codelineno-6-4" name="__codelineno-6-4" href="#__codelineno-6-4"></a>python<span class="w"> </span>run.py<span class="w"> </span>generate-cfg<span class="w"> </span><span class="se">\</span>
</span><span id="__span-6-5"><a id="__codelineno-6-5" name="__codelineno-6-5" href="#__codelineno-6-5"></a><span class="w">    </span>--model_flavor<span class="w"> </span>400M<span class="w"> </span>--batch_size<span class="w"> </span><span class="si">${</span><span class="nv">batch_size</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-6-6"><a id="__codelineno-6-6" name="__codelineno-6-6" href="#__codelineno-6-6"></a><span class="w">    </span>--data_parallel_replicate_degree<span class="w"> </span><span class="si">${</span><span class="nv">data_parallel_replicate</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-6-7"><a id="__codelineno-6-7" name="__codelineno-6-7" href="#__codelineno-6-7"></a><span class="w">    </span>--data_parallel_shard_degree<span class="w"> </span><span class="si">${</span><span class="nv">data_parallel_shard</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-6-8"><a id="__codelineno-6-8" name="__codelineno-6-8" href="#__codelineno-6-8"></a><span class="w">    </span>--compile<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-6-9"><a id="__codelineno-6-9" name="__codelineno-6-9" href="#__codelineno-6-9"></a><span class="w">    </span>--save_path<span class="w"> </span>./configs/tutorial-400M.yaml
</span><span id="__span-6-10"><a id="__codelineno-6-10" name="__codelineno-6-10" href="#__codelineno-6-10"></a>
</span><span id="__span-6-11"><a id="__codelineno-6-11" name="__codelineno-6-11" href="#__codelineno-6-11"></a><span class="nv">num_gpus</span><span class="o">=</span><span class="s2">&quot;8&quot;</span><span class="w"> </span><span class="c1"># 8 GPUs, 1 node</span>
</span><span id="__span-6-12"><a id="__codelineno-6-12" name="__codelineno-6-12" href="#__codelineno-6-12"></a><span class="nv">PYTORCH_CUDA_ALLOC_CONF</span><span class="o">=</span><span class="s2">&quot;expandable_segments:True&quot;</span><span class="w"> </span><span class="nv">STREAM_HF_DATA</span><span class="o">=</span><span class="s2">&quot;1&quot;</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-6-13"><a id="__codelineno-6-13" name="__codelineno-6-13" href="#__codelineno-6-13"></a>torchrun<span class="w"> </span>--nproc_per_node<span class="o">=</span><span class="si">${</span><span class="nv">num_gpus</span><span class="si">}</span><span class="w"> </span>--rdzv_backend<span class="w"> </span>c10d<span class="w"> </span><span class="se">\</span>
</span><span id="__span-6-14"><a id="__codelineno-6-14" name="__codelineno-6-14" href="#__codelineno-6-14"></a><span class="w">    </span>--rdzv_endpoint<span class="o">=</span><span class="s2">&quot;localhost:0&quot;</span><span class="w"> </span>--local-ranks-filter<span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-6-15"><a id="__codelineno-6-15" name="__codelineno-6-15" href="#__codelineno-6-15"></a><span class="w">    </span>--role<span class="w"> </span>rank<span class="w"> </span>--tee<span class="w"> </span><span class="m">3</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-6-16"><a id="__codelineno-6-16" name="__codelineno-6-16" href="#__codelineno-6-16"></a><span class="w">    </span>run.py<span class="w"> </span>pretrain<span class="w"> </span>--config<span class="w"> </span>configs/tutorial-400M.yaml<span class="w"> </span><span class="se">\</span>
</span><span id="__span-6-17"><a id="__codelineno-6-17" name="__codelineno-6-17" href="#__codelineno-6-17"></a><span class="w">    </span>--metrics_args.enable_wandb<span class="w"> </span><span class="nb">false</span>
</span></code></pre></div>
<div class="admonition success">
<p class="admonition-title">Our Pretraining Results</p>
<p>We pretrained the <code>AICrossSim-CLM-400M</code> model on 8 NVIDIA A6000 GPUs for 21 hours.</p>
<ul>
<li>Training config: <a href="https://github.com/AICrossSim/NewComputeBench/blob/master/experiments/llm-bitflip/pretrain/configs/aixsim-200M.yaml"><code>experiments/llm-bitflip/pretrain/configs/aixsim-200M.yaml</code></a></li>
<li>Wandb logs: <a href="https://wandb.ai/cz98/torchtitan/runs/cic7m3cx/overview">link</a></li>
<li>HuggingFace checkpoint: <a href="https://huggingface.co/AICrossSim/clm-400m">AICrossSim/clm-400m</a></li>
</ul>
</div>
<h3 id="aicrosssim-clm-11b">AICrossSim-CLM-1.1B</h3>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-7-1"><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a><span class="nv">batch_size</span><span class="o">=</span><span class="s2">&quot;24&quot;</span>
</span><span id="__span-7-2"><a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a><span class="nv">data_parallel_replicate</span><span class="o">=</span><span class="s2">&quot;1&quot;</span>
</span><span id="__span-7-3"><a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a><span class="nv">data_parallel_shard</span><span class="o">=</span><span class="s2">&quot;8&quot;</span>
</span><span id="__span-7-4"><a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a>python<span class="w"> </span>run.py<span class="w"> </span>generate-cfg<span class="w"> </span><span class="se">\</span>
</span><span id="__span-7-5"><a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a><span class="w">    </span>--model_flavor<span class="w"> </span><span class="m">1</span>.1B<span class="w"> </span>--batch_size<span class="w"> </span><span class="si">${</span><span class="nv">batch_size</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-7-6"><a id="__codelineno-7-6" name="__codelineno-7-6" href="#__codelineno-7-6"></a><span class="w">    </span>--data_parallel_replicate_degree<span class="w"> </span><span class="si">${</span><span class="nv">data_parallel_replicate</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-7-7"><a id="__codelineno-7-7" name="__codelineno-7-7" href="#__codelineno-7-7"></a><span class="w">    </span>--data_parallel_shard_degree<span class="w"> </span><span class="si">${</span><span class="nv">data_parallel_shard</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-7-8"><a id="__codelineno-7-8" name="__codelineno-7-8" href="#__codelineno-7-8"></a><span class="w">    </span>--compile<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-7-9"><a id="__codelineno-7-9" name="__codelineno-7-9" href="#__codelineno-7-9"></a><span class="w">    </span>--save_path<span class="w"> </span>./configs/tutorial-1.1B.yaml
</span><span id="__span-7-10"><a id="__codelineno-7-10" name="__codelineno-7-10" href="#__codelineno-7-10"></a>
</span><span id="__span-7-11"><a id="__codelineno-7-11" name="__codelineno-7-11" href="#__codelineno-7-11"></a><span class="nv">num_gpus</span><span class="o">=</span><span class="s2">&quot;8&quot;</span><span class="w"> </span><span class="c1"># 8 GPUs, 1 node</span>
</span><span id="__span-7-12"><a id="__codelineno-7-12" name="__codelineno-7-12" href="#__codelineno-7-12"></a><span class="nv">PYTORCH_CUDA_ALLOC_CONF</span><span class="o">=</span><span class="s2">&quot;expandable_segments:True&quot;</span><span class="w"> </span><span class="nv">STREAM_HF_DATA</span><span class="o">=</span><span class="s2">&quot;1&quot;</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-7-13"><a id="__codelineno-7-13" name="__codelineno-7-13" href="#__codelineno-7-13"></a>torchrun<span class="w"> </span>--nproc_per_node<span class="o">=</span><span class="si">${</span><span class="nv">num_gpus</span><span class="si">}</span><span class="w"> </span>--rdzv_backend<span class="w"> </span>c10d<span class="w"> </span><span class="se">\</span>
</span><span id="__span-7-14"><a id="__codelineno-7-14" name="__codelineno-7-14" href="#__codelineno-7-14"></a><span class="w">    </span>--rdzv_endpoint<span class="o">=</span><span class="s2">&quot;localhost:0&quot;</span><span class="w"> </span>--local-ranks-filter<span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-7-15"><a id="__codelineno-7-15" name="__codelineno-7-15" href="#__codelineno-7-15"></a><span class="w">    </span>--role<span class="w"> </span>rank<span class="w"> </span>--tee<span class="w"> </span><span class="m">3</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-7-16"><a id="__codelineno-7-16" name="__codelineno-7-16" href="#__codelineno-7-16"></a><span class="w">    </span>run.py<span class="w"> </span>pretrain<span class="w"> </span>--config<span class="w"> </span>configs/tutorial-1.1B.yaml<span class="w"> </span><span class="se">\</span>
</span><span id="__span-7-17"><a id="__codelineno-7-17" name="__codelineno-7-17" href="#__codelineno-7-17"></a><span class="w">    </span>--metrics_args.enable_wandb<span class="w"> </span><span class="nb">false</span>
</span></code></pre></div>
<div class="admonition success">
<p class="admonition-title">Our Pretraining Results</p>
<p>We pretrained the <code>AICrossSim-CLM-1.1B</code> model on 8 NVIDIA H100 96GB GPUs for 33 hours.</p>
<ul>
<li>Training config: <a href="https://github.com/AICrossSim/NewComputeBench/blob/master/experiments/llm-bitflip/pretrain/configs/aixsim-1.1b.yaml"><code>experiments/llm-bitflip/pretrain/configs/aixsim-1.1b.yaml</code></a></li>
<li>Wandb logs: <a href="https://wandb.ai/cz98/torchtitan/runs/8mcf8ay1/overview">link</a></li>
<li>HuggingFace checkpoint: <a href="https://huggingface.co/AICrossSim/clm-1.1b">AICrossSim/clm-1.1b</a></li>
<li>We also stored the raw torchrun checkpoints in the HuggingFace repo in case we need to resume pretraining later. You can find them <a href="https://huggingface.co/AICrossSim/clm-1.1b-torch-ckpt">here</a></li>
</ul>
</div>
<h2 id="evaluation">Evaluation</h2>
<h3 id="pretraining-dataset-perplexity">Pretraining Dataset Perplexity</h3>
<p>We provide subcommands to evaluate the torchrun or HuggingFace checkpoints on the pretraining dataset.</p>
<ul>
<li>Torchrun checkpoint
    <div class="language-bash highlight"><pre><span></span><code><span id="__span-8-1"><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a>python<span class="w"> </span>run.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>pt-ppl<span class="w"> </span><span class="se">\</span>
</span><span id="__span-8-2"><a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a><span class="w">    </span>aixsim<span class="w"> </span>60M<span class="w"> </span><span class="se">\</span>
</span><span id="__span-8-3"><a id="__codelineno-8-3" name="__codelineno-8-3" href="#__codelineno-8-3"></a><span class="w">    </span>./outputs/checkpoints/aixsim-60M/&lt;timestamp&gt;/&lt;step-xxx&gt;<span class="w">  </span><span class="c1"># path to torchrun checkpoint</span>
</span></code></pre></div></li>
<li>HuggingFace checkpoint
    <div class="language-bash highlight"><pre><span></span><code><span id="__span-9-1"><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a>python<span class="w"> </span>run.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>hf-ppl<span class="w"> </span><span class="se">\</span>
</span><span id="__span-9-2"><a id="__codelineno-9-2" name="__codelineno-9-2" href="#__codelineno-9-2"></a><span class="w">    </span>AICrossSim/clm-60m<span class="w">  </span><span class="c1"># path to local HuggingFace checkpoint or HuggingFace repo name</span>
</span></code></pre></div></li>
</ul>
<h3 id="downstream-tasks">Downstream Tasks</h3>
<p>We leverage <a href="https://github.com/EleutherAI/lm-evaluation-harness"><code>lm-eval-harness</code></a> to evaluate the pretrained models on various tasks.</p>
<p>For example,
<div class="language-bash highlight"><pre><span></span><code><span id="__span-10-1"><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a><span class="nv">model_name</span><span class="o">=</span><span class="s2">&quot;AICrossSim/clm-60m&quot;</span><span class="w"> </span><span class="c1"># Path to local HuggingFace checkpoint or HuggingFace repo name</span>
</span><span id="__span-10-2"><a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a>python<span class="w"> </span>run.py<span class="w"> </span><span class="nb">eval</span><span class="w"> </span>hf-lm-eval<span class="w"> </span><span class="se">\</span>
</span><span id="__span-10-3"><a id="__codelineno-10-3" name="__codelineno-10-3" href="#__codelineno-10-3"></a><span class="w">    </span><span class="si">${</span><span class="nv">model_name</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-10-4"><a id="__codelineno-10-4" name="__codelineno-10-4" href="#__codelineno-10-4"></a><span class="w">    </span>--tasks<span class="w"> </span><span class="o">[</span><span class="s1">&#39;wikitext&#39;</span><span class="o">]</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-10-5"><a id="__codelineno-10-5" name="__codelineno-10-5" href="#__codelineno-10-5"></a><span class="w">    </span>--dtype<span class="w"> </span>float16
</span></code></pre></div></p>
<p>Try <code>--help</code> to see all the available arguments.</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-11-1"><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a>python<span class="w"> </span>run.py<span class="w"> </span>hf-lm-eval<span class="w"> </span>-h
</span></code></pre></div>
<div class="admonition info">
<p class="admonition-title"><code>lm-eval-harness</code></p>
<p>Under the hood, the subcommand <code>hf-lm-eval</code> uses <code>lm-eval-harness</code>'s <code>simple_evaluate</code> function, thus it accepts several arguments of <code>simple_evaluate</code>:</p>
<ul>
<li><code>--tasks</code>: a list of tasks to evaluate on. The task names are the same as those in <code>lm-eval-harness</code>.</li>
<li><code>--num_fewshot</code>: some downstream tasks support few-shot evaluation. Default <code>None</code> means default few-shot setting.</li>
<li><code>--limit</code>: If <code>--limit</code> &gt; 1, it's the maximum number of examples to evaluate on, else it denotes the fraction of the dataset to evaluate on. Default <code>None</code> means evaluate on the entire dataset.</li>
</ul>
</div>
<h3 id="simple-generation">Simple Generation</h3>
<p>We also provide a simple generation subcommand <code>hf-gen</code> to generate text using the pretrained models.</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-12-1"><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a><span class="nv">prompt</span><span class="o">=</span><span class="s2">&quot;London is&quot;</span>
</span><span id="__span-12-2"><a id="__codelineno-12-2" name="__codelineno-12-2" href="#__codelineno-12-2"></a><span class="nv">max_new_tokens</span><span class="o">=</span><span class="s2">&quot;100&quot;</span>
</span><span id="__span-12-3"><a id="__codelineno-12-3" name="__codelineno-12-3" href="#__codelineno-12-3"></a><span class="nv">do_sample</span><span class="o">=</span><span class="s2">&quot;true&quot;</span>
</span><span id="__span-12-4"><a id="__codelineno-12-4" name="__codelineno-12-4" href="#__codelineno-12-4"></a><span class="nv">temperature</span><span class="o">=</span><span class="s2">&quot;0.6&quot;</span>
</span><span id="__span-12-5"><a id="__codelineno-12-5" name="__codelineno-12-5" href="#__codelineno-12-5"></a><span class="nv">top_k</span><span class="o">=</span><span class="s2">&quot;50&quot;</span>
</span><span id="__span-12-6"><a id="__codelineno-12-6" name="__codelineno-12-6" href="#__codelineno-12-6"></a><span class="nv">top_p</span><span class="o">=</span><span class="s2">&quot;0.9&quot;</span>
</span><span id="__span-12-7"><a id="__codelineno-12-7" name="__codelineno-12-7" href="#__codelineno-12-7"></a>
</span><span id="__span-12-8"><a id="__codelineno-12-8" name="__codelineno-12-8" href="#__codelineno-12-8"></a>python<span class="w"> </span>run.py<span class="w"> </span>hf-gen<span class="w"> </span><span class="se">\</span>
</span><span id="__span-12-9"><a id="__codelineno-12-9" name="__codelineno-12-9" href="#__codelineno-12-9"></a><span class="w">    </span>--model_name<span class="w"> </span>AICrossSim/clm-60m<span class="w"> </span><span class="se">\</span>
</span><span id="__span-12-10"><a id="__codelineno-12-10" name="__codelineno-12-10" href="#__codelineno-12-10"></a><span class="w">    </span>--prompt<span class="w"> </span><span class="s2">&quot;</span><span class="si">${</span><span class="nv">prompt</span><span class="si">}</span><span class="s2">&quot;</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-12-11"><a id="__codelineno-12-11" name="__codelineno-12-11" href="#__codelineno-12-11"></a><span class="w">    </span>--max_new_tokens<span class="w"> </span><span class="si">${</span><span class="nv">max_new_tokens</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-12-12"><a id="__codelineno-12-12" name="__codelineno-12-12" href="#__codelineno-12-12"></a><span class="w">    </span>--do_sample<span class="w"> </span><span class="si">${</span><span class="nv">do_sample</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-12-13"><a id="__codelineno-12-13" name="__codelineno-12-13" href="#__codelineno-12-13"></a><span class="w">    </span>--temperature<span class="w"> </span><span class="si">${</span><span class="nv">temperature</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-12-14"><a id="__codelineno-12-14" name="__codelineno-12-14" href="#__codelineno-12-14"></a><span class="w">    </span>--top_k<span class="w"> </span><span class="si">${</span><span class="nv">top_k</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
</span><span id="__span-12-15"><a id="__codelineno-12-15" name="__codelineno-12-15" href="#__codelineno-12-15"></a><span class="w">    </span>--top_p<span class="w"> </span><span class="si">${</span><span class="nv">top_p</span><span class="si">}</span>
</span></code></pre></div>







  
    
  
  
    
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Last update">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="April 20, 2025 13:52:17">April 20, 2025</span>
  </span>

    
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Created">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="April 20, 2025 13:52:17">April 20, 2025</span>
  </span>

    
    
    
      
  <span class="md-source-file__fact">
    
      
  <span class="md-icon" title="Contributors">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34-.46-1.16-1.11-1.47-1.11-1.47-.91-.62.07-.6.07-.6 1 .07 1.53 1.03 1.53 1.03.87 1.52 2.34 1.07 2.91.83.09-.65.35-1.09.63-1.34-2.22-.25-4.55-1.11-4.55-4.92 0-1.11.38-2 1.03-2.71-.1-.25-.45-1.29.1-2.64 0 0 .84-.27 2.75 1.02.79-.22 1.65-.33 2.5-.33s1.71.11 2.5.33c1.91-1.29 2.75-1.02 2.75-1.02.55 1.35.2 2.39.1 2.64.65.71 1.03 1.6 1.03 2.71 0 3.82-2.34 4.66-4.57 4.91.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2"/></svg>
  </span>
  <span>GitHub</span>

    
    <nav>
      
        <a href="https://github.com/przemekff" class="md-author" title="@przemekff">
          
          <img src="https://avatars.githubusercontent.com/u/56603889?v=4&size=72" alt="przemekff">
        </a>
      
        <a href="https://github.com/web-flow" class="md-author" title="@web-flow">
          
          <img src="https://avatars.githubusercontent.com/u/19864447?v=4&size=72" alt="web-flow">
        </a>
      
        <a href="https://github.com/ChengZhang-98" class="md-author" title="@ChengZhang-98">
          
          <img src="https://avatars.githubusercontent.com/u/102538889?v=4&size=72" alt="ChengZhang-98">
        </a>
      
      
      
    </nav>
  </span>

    
  </aside>





                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-progress" data-md-component="progress" role="progressbar"></div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.instant", "navigation.instant.progress", "navigation.tabs", "navigation.tabs.sticky", "navigation.path", "toc.integrate", "toc.follow", "search.highlight", "search.suggest", "search.share", "content.action.edit", "content.action.view", "content.code.copy", "content.code.select"], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.c8b220af.min.js"></script>
      
    
  </body>
</html>