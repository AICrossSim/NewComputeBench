activation_checkpoint_args:
  mode: selective
  selective_ac_option: "2"
checkpoint_args:
  async_mode: disabled
  create_seed_checkpoint: false
  enable_checkpoint: true
  exclude_from_loading: []
  export_dtype: float32
  folder: 20250411-125027
  interval: 500
  interval_type: steps
  keep_latest_k: 3
  load_step: -1
  model_weights_only: false
comm_args:
  init_timeout_seconds: 300
  trace_buf_size: 20000
  train_timeout_seconds: 100
experimental_args:
  context_parallel_degree: 1
  context_parallel_rotate_method: allgather
  enable_async_tensor_parallel: false
  enable_compiled_autograd: false
  pipeline_parallel_degree: 1
  pipeline_parallel_microbatches: null
  pipeline_parallel_schedule: 1F1B
  pipeline_parallel_schedule_csv: ""
  pipeline_parallel_split_points: []
float8_args:
  enable_float8_linear: false
  enable_fsdp_float8_all_gather: false
  precompute_float8_dynamic_scale_for_fsdp: false
job_args:
  description: Pretrain aixsim debug
  dump_folder: outputs/checkpoints/aixsim-debug
  print_args: false
  use_for_integration_test: false
memory_estimation_args:
  disable_fake_mode: false
  enabled: false
metrics_args:
  disable_color_printing: false
  enable_tensorboard: false
  enable_wandb: true
  log_freq: 10
  rank_0_only: true
  save_tb_folder: tb
model_args:
  flavor: debug
  name: aixsim
  norm_type: rmsnorm
  tokenizer_path: HuggingFaceTB/cosmo2-tokenizer
optimizer_args:
  early_step_in_backward: false
  fused: false
  lr: 0.0001
  name: AdamW
profiling_args:
  enable_memory_snapshot: false
  enable_profiling: false
  profile_freq: 10
  save_memory_snapshot_folder: memory_snapshot
  save_traces_folder: profile_traces
training_args:
  batch_size: 8
  compile: false
  data_parallel_replicate_degree: 1
  data_parallel_shard_degree: -1
  dataset: fineweb-edu
  dataset_path: HuggingFaceFW/fineweb-edu
  deterministic: false
  disable_loss_parallel: false
  enable_cpu_offload: false
  fsdp_reshard_after_forward: default
  gc_freq: 50
  max_norm: 1.0
  mixed_precision_param: bfloat16
  mixed_precision_reduce: float32
  seed: 42
  seq_len: 2048
  steps: 208
  tensor_parallel_degree: 1
  warmup_steps: 41
transform_args:
  layer_name_to_config:
    default: null
    ? layers\.[0-9]+\.attention|layers\.[0-9]+\.attention\.(wq|wk|wv|wo)|layers\.[0-9]+\.feed_forward\.(w1|w2|w3)
    : q_bypass: false
      q_init_seed: 0
      q_levels: 256
      q_lut_min: 0.02004
      q_quantiles: null
      q_smooth_factor: 0.9
    output: null
  use_regex: true
