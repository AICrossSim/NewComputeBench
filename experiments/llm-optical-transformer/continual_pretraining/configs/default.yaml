use_regex: true
layer_name_to_config:
  'model\.layers\.[0-9]+\.self_attn':
    q_levels: 256
    q_lut_min: 0.020040
    q_quantiles: null
    q_smooth_factor: 0.9
    q_init_seed: 0
    q_bypass: false
  'model\.layers.[0-9]+\.self_attn\.(q|k|v|o)_proj': &fc_cfg
    q_levels: 256
    q_lut_min: 0.020040
    q_quantiles: null
    q_smooth_factor: 0.9
    q_init_seed: 0
    q_bypass: false
  'model\.layers\.[0-9]+\.mlp\.(gate|up|down)_proj':
    <<: *fc_cfg
  "lm_head": null
